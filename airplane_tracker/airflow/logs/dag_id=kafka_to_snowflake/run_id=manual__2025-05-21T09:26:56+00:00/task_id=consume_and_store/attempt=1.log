[2025-05-21T09:26:57.718+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: kafka_to_snowflake.consume_and_store manual__2025-05-21T09:26:56+00:00 [queued]>
[2025-05-21T09:26:57.722+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: kafka_to_snowflake.consume_and_store manual__2025-05-21T09:26:56+00:00 [queued]>
[2025-05-21T09:26:57.722+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2025-05-21T09:26:57.728+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): consume_and_store> on 2025-05-21 09:26:56+00:00
[2025-05-21T09:26:57.731+0000] {standard_task_runner.py:57} INFO - Started process 347 to run task
[2025-05-21T09:26:57.734+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'kafka_to_snowflake', 'consume_and_store', 'manual__2025-05-21T09:26:56+00:00', '--job-id', '39', '--raw', '--subdir', 'DAGS_FOLDER/kafka_to_snowflake.py', '--cfg-path', '/tmp/tmpy6c_k5zf']
[2025-05-21T09:26:57.736+0000] {standard_task_runner.py:85} INFO - Job 39: Subtask consume_and_store
[2025-05-21T09:26:57.743+0000] {logging_mixin.py:154} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-21T09:26:57.758+0000] {task_command.py:416} INFO - Running <TaskInstance: kafka_to_snowflake.consume_and_store manual__2025-05-21T09:26:56+00:00 [running]> on host 181c87754ed7
[2025-05-21T09:26:57.803+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='kafka_to_snowflake' AIRFLOW_CTX_TASK_ID='consume_and_store' AIRFLOW_CTX_EXECUTION_DATE='2025-05-21T09:26:56+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-21T09:26:56+00:00'
[2025-05-21T09:26:57.804+0000] {kafka_to_snowflake.py:58} INFO - Starting Kafka → Snowflake ingestion
[2025-05-21T09:26:57.806+0000] {conn.py:396} INFO - <BrokerConnection client_id=kafka-python-2.2.7, node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.18.0.3', 29092)]>: connecting to kafka:29092 [('172.18.0.3', 29092) IPv4]
[2025-05-21T09:26:57.810+0000] {conn.py:618} INFO - <BrokerConnection client_id=kafka-python-2.2.7, node_id=bootstrap-0 host=kafka:29092 <checking_api_versions_recv> [IPv4 ('172.18.0.3', 29092)]>: Broker version identified as 2.6
[2025-05-21T09:26:57.810+0000] {conn.py:457} INFO - <BrokerConnection client_id=kafka-python-2.2.7, node_id=bootstrap-0 host=kafka:29092 <connected> [IPv4 ('172.18.0.3', 29092)]>: Connection complete.
[2025-05-21T09:26:57.811+0000] {consumer.py:120} WARNING - group_id is None: disabling auto-commit.
[2025-05-21T09:26:57.811+0000] {subscription_state.py:177} INFO - Updating subscribed topics to: ('flights',)
[2025-05-21T09:26:57.812+0000] {subscription_state.py:246} INFO - Updated partition assignment: [('flights', 0)]
[2025-05-21T09:26:57.813+0000] {conn.py:396} INFO - <BrokerConnection client_id=kafka-python-2.2.7, node_id=1001 host=kafka:29092 <connecting> [IPv4 ('172.18.0.3', 29092)]>: connecting to kafka:29092 [('172.18.0.3', 29092) IPv4]
[2025-05-21T09:26:57.813+0000] {conn.py:457} INFO - <BrokerConnection client_id=kafka-python-2.2.7, node_id=1001 host=kafka:29092 <connected> [IPv4 ('172.18.0.3', 29092)]>: Connection complete.
[2025-05-21T09:26:57.813+0000] {conn.py:945} INFO - <BrokerConnection client_id=kafka-python-2.2.7, node_id=bootstrap-0 host=kafka:29092 <connected> [IPv4 ('172.18.0.3', 29092)]>: Closing connection. 
[2025-05-21T09:26:57.816+0000] {fetcher.py:413} INFO - Resetting offset for partition ('flights', 0) to offset 0.
[2025-05-21T09:27:07.980+0000] {conn.py:945} INFO - <BrokerConnection client_id=kafka-python-2.2.7, node_id=1001 host=kafka:29092 <connected> [IPv4 ('172.18.0.3', 29092)]>: Closing connection. 
[2025-05-21T09:27:07.982+0000] {fetcher.py:779} INFO - Fetch to node 1001 failed: Cancelled: <BrokerConnection client_id=kafka-python-2.2.7, node_id=1001 host=kafka:29092 <connected> [IPv4 ('172.18.0.3', 29092)]>
[2025-05-21T09:27:07.983+0000] {kafka_to_snowflake.py:84} INFO - Consumed 4000 messages from Kafka
[2025-05-21T09:27:07.984+0000] {connection.py:334} INFO - Snowflake Connector for Python Version: 3.3.1, Python Version: 3.8.18, Platform: Linux-6.10.14-linuxkit-aarch64-with-glibc2.17
[2025-05-21T09:27:07.985+0000] {connection.py:1103} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-05-21T09:27:07.986+0000] {connection.py:1121} INFO - Setting use_openssl_only mode to False
[2025-05-21T09:27:09.342+0000] {cursor.py:833} INFO - query: [INSERT INTO PUBLIC.aircraft_raw (icao24, callsign, origin_country, longitude, la...]
[2025-05-21T09:27:12.934+0000] {cursor.py:846} INFO - query execution done
[2025-05-21T09:27:12.940+0000] {kafka_to_snowflake.py:107} INFO - Inserted 4000 raw rows
[2025-05-21T09:27:12.940+0000] {cursor.py:833} INFO - query: [INSERT INTO PUBLIC.aircraft_summary (run_time, origin_country, aircraft_count, a...]
[2025-05-21T09:27:13.200+0000] {cursor.py:846} INFO - query execution done
[2025-05-21T09:27:13.207+0000] {kafka_to_snowflake.py:131} ERROR - Snowflake load failed
Traceback (most recent call last):
  File "/opt/airflow/dags/kafka_to_snowflake.py", line 123, in consume_and_store
    cursor.executemany(insert_summary_sql, summary_rows)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 1201, in executemany
    self.execute(command, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 937, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): 01bc7e57-0205-54a5-0006-75e30014b7de: SQL compilation error:
Table 'AIRPLANE_TRACKER_DB.PUBLIC.AIRCRAFT_SUMMARY' does not exist or not authorized.
[2025-05-21T09:27:13.449+0000] {kafka_to_snowflake.py:51} INFO - Telegram notification sent: ❌ *Ingestion failed* at 2025-05-21 09:27:07 UTC: | ``` | 002003 (42S02): 01bc7e57-0205-54a5-0006-75e30014b7de: SQL compilation error: | Table 'AIRPLANE_TRACKER_DB.PUBLIC.AIRCRAFT_SUMMARY' does not exist or not authorized. | ```
[2025-05-21T09:27:13.452+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/kafka_to_snowflake.py", line 123, in consume_and_store
    cursor.executemany(insert_summary_sql, summary_rows)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 1201, in executemany
    self.execute(command, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 937, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): 01bc7e57-0205-54a5-0006-75e30014b7de: SQL compilation error:
Table 'AIRPLANE_TRACKER_DB.PUBLIC.AIRCRAFT_SUMMARY' does not exist or not authorized.
[2025-05-21T09:27:13.468+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=kafka_to_snowflake, task_id=consume_and_store, execution_date=20250521T092656, start_date=20250521T092657, end_date=20250521T092713
[2025-05-21T09:27:13.487+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 39 for task consume_and_store (002003 (42S02): 01bc7e57-0205-54a5-0006-75e30014b7de: SQL compilation error:
Table 'AIRPLANE_TRACKER_DB.PUBLIC.AIRCRAFT_SUMMARY' does not exist or not authorized.; 347)
[2025-05-21T09:27:13.498+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2025-05-21T09:27:13.514+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
